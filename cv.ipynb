{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1226872",
   "metadata": {},
   "source": [
    "## Reading the Images\n",
    "\n",
    "<ol><li>Image-> 2d grid of pixels.\n",
    "<li>Pixel-> color/grayscale dots or matrix of numbers. Smallest unit of Image. RGB values\n",
    "<li>Width and Height -> Total no. of pixels horizontally and vertically.\n",
    "<li>Color Channels -> A channel stores one part of color info for each pixel. in opencv BGR (Blue, Green, Red order - reversed from standard RGB). Grayscale images have 1 channel, color images have 3 channels, images with transparency (alpha) have 4 channels (BGRA).\n",
    "<li>Image Format -> \n",
    "<ul>\n",
    "<li>jpg/jpeg = small file size. Uses lossy compression (some quality loss). Good for photographs. No transparency support.\n",
    "                <li>png = high quality. Supports Transparency. Uses lossless compression. Larger file size than jpg. Good for graphics, logos, screenshots.\n",
    "                <li>bmp = Uncompressed or minimally compressed. Very large file size. Fast to read/write. Simple format with no quality loss.\n",
    "                <li>tiff = super high res. Supports multiple pages/layers. Can be compressed or uncompressed. Used in professional photography, medical imaging, and document scanning.\n",
    "                </ul>\n",
    "<li>Reading Images in OpenCV:\n",
    "<ul>\n",
    "<li>cv2.imread(filepath, flag) - reads image from file\n",
    "<li>Flags: cv2.IMREAD_COLOR/1 (default, BGR), cv2.IMREAD_GRAYSCALE/0 (grayscale), cv2.IMREAD_UNCHANGED/-1 (with alpha channel)\n",
    "<li>Returns numpy array with shape (height, width, channels)\n",
    "<li>cv2.imshow(window_name, image) - displays image\n",
    "<li>cv2.waitKey(delay) - waits for key press (0 = wait indefinitely)\n",
    "<li>cv2.destroyAllWindows() - closes all windows\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d71a2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not found\\n.\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafff71",
   "metadata": {},
   "source": [
    "## Display Images\n",
    "\n",
    "<ol>\n",
    "<li><b>cv2.imshow(window_name, image)</b>\n",
    "<ul>\n",
    "<li>Displays an image in a window\n",
    "<li>window_name: String that names the window (used to reference it later)\n",
    "<li>image: numpy array containing the image data\n",
    "<li>Creates a new window if window_name doesn't exist, reuses existing window if it does\n",
    "<li>Window size automatically adjusts to image dimensions by default\n",
    "<li>Multiple images can be displayed by calling imshow() multiple times with different window names\n",
    "</ul>\n",
    "\n",
    "<li><b>cv2.waitKey(delay)</b>\n",
    "<ul>\n",
    "<li>Waits for a keyboard key press for specified milliseconds\n",
    "<li>delay: Time in milliseconds (0 = wait indefinitely until key press)\n",
    "<li>Returns the ASCII value of the key pressed, or -1 if no key was pressed within delay time\n",
    "<li>Required for image windows to display properly - without it, window appears and closes immediately\n",
    "<li>Common usage: cv2.waitKey(0) to wait until user presses any key\n",
    "<li>Can check specific keys: if cv2.waitKey(0) & 0xFF == ord('q'): to detect 'q' key\n",
    "<li>Also handles GUI events (window dragging, resizing, etc.)\n",
    "</ul>\n",
    "\n",
    "<li><b>cv2.destroyAllWindows()</b>\n",
    "<ul>\n",
    "<li>Closes all OpenCV windows that were created\n",
    "<li>Releases memory allocated for the windows\n",
    "<li>Good practice to call at end of program to cleanup\n",
    "<li>Alternative: cv2.destroyWindow(window_name) to close a specific window\n",
    "<li>Should be called after waitKey() to ensure windows close properly\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829212dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not found\\n.\")\n",
    "else:\n",
    "    cv2.imshow(\"Image\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf96d4",
   "metadata": {},
   "source": [
    "## Saving the image.\n",
    "\n",
    "<ol>\n",
    "<li><b>cv2.imwrite(filename, image, params)</b>\n",
    "<ul>\n",
    "<li>Saves an image to a specified file\n",
    "<li>filename: String specifying the path and name of the output file. The file format is determined by the extension (.jpg, .png, .bmp, etc.)\n",
    "<li>image: numpy array containing the image data to be saved\n",
    "<li>params (optional): Format-specific parameters passed as pairs\n",
    "<li>Returns: True if image is successfully saved, False otherwise\n",
    "<li>Automatically creates the file if it doesn't exist, overwrites if it does\n",
    "<li>The directory path must exist - imwrite won't create folders\n",
    "</ul>\n",
    "\n",
    "<li><b>Common params for different formats:</b>\n",
    "<ul>\n",
    "<li>For JPEG: cv2.IMWRITE_JPEG_QUALITY (0-100, default 95). Higher = better quality, larger file\n",
    "<li>For PNG: cv2.IMWRITE_PNG_COMPRESSION (0-9, default 3). Higher = smaller file, slower to save\n",
    "<li>Example: cv2.imwrite('output.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "</ul>\n",
    "\n",
    "<li><b>Important Notes:</b>\n",
    "<ul>\n",
    "<li>Image format is automatically detected from the file extension\n",
    "<li>If saving in different format than original, some conversions may occur\n",
    "<li>OpenCV saves images in BGR format (same as it reads them)\n",
    "<li>Alpha channel (transparency) is only preserved in formats that support it (PNG, TIFF)\n",
    "<li>Always check the return value to ensure save was successful\n",
    "</ul>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d975e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved Successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not found\\n.\")\n",
    "else:\n",
    "    success  = cv2.imwrite(\"output.png\",image)\n",
    "    if success:\n",
    "        print(\"Image saved Successfully\")\n",
    "    else:\n",
    "        print(\"failed to save image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da4928",
   "metadata": {},
   "source": [
    "## Image Dimensions.\n",
    "\n",
    "<ol>\n",
    "<li><b>.shape attribute</b>\n",
    "<ul>\n",
    "<li>Returns a tuple containing the dimensions of the image array\n",
    "<li>Syntax: dimensions = image.shape\n",
    "<li>This is a NumPy array attribute (OpenCV images are NumPy arrays)\n",
    "<li>Does not require parentheses - it's an attribute, not a method\n",
    "</ul>\n",
    "\n",
    "<li><b>For Color Images: Returns (height, width, channels)</b>\n",
    "<ul>\n",
    "<li>height: Number of rows/pixels vertically (y-axis)\n",
    "<li>width: Number of columns/pixels horizontally (x-axis)\n",
    "<li>channels: Number of color channels (typically 3 for BGR, 4 for BGRA)\n",
    "<li>Example: (480, 640, 3) means 480 pixels tall, 640 pixels wide, 3 color channels\n",
    "</ul>\n",
    "\n",
    "<li><b>For Grayscale Images: Returns (height, width)</b>\n",
    "<ul>\n",
    "<li>Only two values since there's only one channel\n",
    "<li>No third dimension in the tuple\n",
    "<li>Example: (480, 640) means 480 pixels tall, 640 pixels wide\n",
    "</ul>\n",
    "\n",
    "<li><b>Accessing Individual Dimensions:</b>\n",
    "<ul>\n",
    "<li>height = image.shape[0]\n",
    "<li>width = image.shape[1]\n",
    "<li>channels = image.shape[2] (only for color images - will cause IndexError on grayscale)\n",
    "<li>To safely get channels: channels = image.shape[2] if len(image.shape) == 3 else 1\n",
    "</ul>\n",
    "\n",
    "<li><b>Related Attributes:</b>\n",
    "<ul>\n",
    "<li>image.size - Total number of pixels (height × width × channels)\n",
    "<li>image.dtype - Data type of pixel values (usually uint8 for 0-255 range)\n",
    "<li>image.ndim - Number of dimensions (2 for grayscale, 3 for color)\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c1a040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Loaded:\n",
      "Height: 225\n",
      "Width: 225\n",
      "Channels: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not found\\n.\")\n",
    "else:\n",
    "    h,w,c = *image.shape[:2], image.ndim \n",
    "    print(f\"Image Loaded:\\nHeight: {h}\\nWidth: {w}\\nChannels: {c}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc4dda",
   "metadata": {},
   "source": [
    "## Grayscale Conversion.\n",
    "\n",
    "<ol>\n",
    "<li><b>Why Convert to Grayscale?</b>\n",
    "<ul>\n",
    "<li>Reducing the channels improves the performance - processes 1 channel instead of 3\n",
    "<li>Reduces memory usage by approximately 66% (1 channel vs 3 channels)\n",
    "<li>Simplifies many computer vision algorithms (edge detection, thresholding, feature detection)\n",
    "<li>Faster computation time for image processing operations\n",
    "<li>Color information is often unnecessary for many CV tasks like object detection, OCR\n",
    "<li>Removes color bias and focuses on intensity/brightness information\n",
    "</ul>\n",
    "\n",
    "<li><b>cv2.cvtColor(image, conversion_code)</b>\n",
    "<ul>\n",
    "<li>Converts an image from one color space to another\n",
    "<li>image: Input image (numpy array)\n",
    "<li>conversion_code: Specifies the type of conversion to perform\n",
    "<li>Returns: Converted image as a numpy array\n",
    "<li>Most versatile function for color space conversions in OpenCV\n",
    "</ul>\n",
    "\n",
    "<li><b>cv2.COLOR_BGR2GRAY</b>\n",
    "<ul>\n",
    "<li>Conversion code to convert BGR color image to grayscale\n",
    "<li>Formula used: Gray = 0.299×Red + 0.587×Green + 0.114×Blue (weighted average)\n",
    "<li>Green has highest weight because human eyes are most sensitive to green\n",
    "<li>Output: Single channel image with values 0-255 (0 = black, 255 = white)\n",
    "<li>Syntax: gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "</ul>\n",
    "\n",
    "<li><b>Alternative Methods:</b>\n",
    "<ul>\n",
    "<li>cv2.imread(filepath, cv2.IMREAD_GRAYSCALE) - Read image as grayscale directly\n",
    "<li>cv2.imread(filepath, 0) - Same as above (0 is shorthand for IMREAD_GRAYSCALE)\n",
    "<li>More efficient to read as grayscale directly if you don't need color version\n",
    "</ul>\n",
    "\n",
    "<li><b>Other Common Color Conversions:</b>\n",
    "<ul>\n",
    "<li>cv2.COLOR_BGR2RGB - BGR to RGB (for displaying with matplotlib)\n",
    "<li>cv2.COLOR_BGR2HSV - BGR to HSV color space (useful for color-based segmentation)\n",
    "<li>cv2.COLOR_GRAY2BGR - Grayscale to BGR (converts back to 3-channel, but still grayscale visually)\n",
    "<li>cv2.COLOR_BGR2LAB - BGR to LAB color space (perceptually uniform)\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not found\\n.\")\n",
    "else:\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"Grayscale Image\",gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a56d4c",
   "metadata": {},
   "source": [
    "# Resizing and Scaling the Images \n",
    "\n",
    "<ol>\n",
    "<li><b>cv2.resize(src, dsize, fx, fy, interpolation)</b>\n",
    "<ul>\n",
    "<li>Resizes an image to a specified size or by a scaling factor\n",
    "<li>Returns: Resized image as a numpy array\n",
    "<li>Can specify exact dimensions OR scaling factors, not both simultaneously\n",
    "</ul>\n",
    "\n",
    "<li><b>Parameters:</b>\n",
    "<ul>\n",
    "<li><b>src:</b> Source/input image to be resized\n",
    "<li><b>dsize:</b> Desired output size as tuple (width, height). Use None if using fx and fy instead (optional)\n",
    "<li><b>fx:</b> Scale factor along horizontal axis. Example: fx=0.5 halves width (optional, default = 0)\n",
    "<li><b>fy:</b> Scale factor along vertical axis. Example: fy=2.0 doubles height (optional, default = 0)\n",
    "<li><b>interpolation:</b> Method used to interpolate pixel values (optional, default = cv2.INTER_LINEAR)\n",
    "</ul>\n",
    "\n",
    "<li><b>Usage Methods:</b>\n",
    "<ul>\n",
    "<li><b>Method 1 - Exact Dimensions:</b> resized = cv2.resize(image, (width, height))\n",
    "<li><b>Method 2 - Scale Factors:</b> resized = cv2.resize(image, None, fx=0.5, fy=0.5)\n",
    "<li>Note: dsize uses (width, height) order, opposite of shape which is (height, width)\n",
    "</ul>\n",
    "\n",
    "<li><b>Interpolation Methods:</b>\n",
    "<ul>\n",
    "<li><b>cv2.INTER_LINEAR:</b> Bilinear interpolation (default). Good balance of speed and quality. Best for enlarging images.\n",
    "<li><b>cv2.INTER_NEAREST:</b> Nearest neighbor interpolation. Fastest but lowest quality. Produces blocky results.\n",
    "<li><b>cv2.INTER_AREA:</b> Resampling using pixel area relation. Best for shrinking/downscaling images. Produces smoother results.\n",
    "<li><b>cv2.INTER_CUBIC:</b> Bicubic interpolation over 4×4 neighborhood. Slower but higher quality. Good for enlarging.\n",
    "<li><b>cv2.INTER_LANCZOS4:</b> Lanczos interpolation over 8×8 neighborhood. Highest quality but slowest. Best for significant enlargement.\n",
    "</ul>\n",
    "\n",
    "<li><b>Common Use Cases:</b>\n",
    "<ul>\n",
    "<li>Standardizing image sizes for machine learning (all inputs same dimension)\n",
    "<li>Creating thumbnails (downscaling with INTER_AREA)\n",
    "<li>Fitting images to display windows\n",
    "<li>Data augmentation in training datasets\n",
    "<li>Reducing processing time by working with smaller images\n",
    "</ul>\n",
    "\n",
    "<li><b>Important Notes:</b>\n",
    "<ul>\n",
    "<li>Upscaling (enlarging) cannot add detail that wasn't in original - results in blurry/pixelated images\n",
    "<li>Downscaling loses information permanently\n",
    "<li>Maintain aspect ratio to avoid distortion: calculate one dimension based on the other\n",
    "<li>For downscaling, use INTER_AREA; for upscaling, use INTER_CUBIC or INTER_LINEAR\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720b7e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Loaded\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"Image not found\")\n",
    "else:\n",
    "    print(\"Image Loaded\")\n",
    "\n",
    "    resized = cv2.resize(image,(300,300))\n",
    "    cv2.imshow(\"Original Image\", image)\n",
    "    cv2.imshow(\"Resized Image\", resized)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20a1e09",
   "metadata": {},
   "source": [
    "## Cropping Images using Slicing in OpenCV\n",
    "\n",
    "<ol>\n",
    "<li><b>Basic Syntax:</b>\n",
    "<ul>\n",
    "<li>cropped_image = image[startY:endY, startX:endX]\n",
    "<li>Uses NumPy array slicing since OpenCV images are NumPy arrays\n",
    "<li>No special OpenCV function needed - pure Python slicing\n",
    "</ul>\n",
    "\n",
    "<li><b>Parameters Explanation:</b>\n",
    "<ul>\n",
    "<li><b>startY:</b> Starting row index (top of crop region)\n",
    "<li><b>endY:</b> Ending row index (bottom of crop region, exclusive)\n",
    "<li><b>startX:</b> Starting column index (left of crop region)\n",
    "<li><b>endX:</b> Ending column index (right of crop region, exclusive)\n",
    "<li>Format: image[rows, columns] which is image[y-coordinates, x-coordinates]\n",
    "<li>Note: Y comes before X (height before width) - follows NumPy convention\n",
    "</ul>\n",
    "\n",
    "<li><b>How Slicing Works:</b>\n",
    "<ul>\n",
    "<li>Indexing starts at 0 (top-left corner is [0, 0])\n",
    "<li>End indices are exclusive (endY and endX are not included in crop)\n",
    "<li>Cropped region height = endY - startY\n",
    "<li>Cropped region width = endX - startX\n",
    "<li>Creates a view/reference to original array by default (not a copy)\n",
    "<li>Use .copy() to create independent copy: cropped_image = image[startY:endY, startX:endX].copy()\n",
    "</ul>\n",
    "\n",
    "<li><b>Examples:</b>\n",
    "<ul>\n",
    "<li>Crop top-left corner (100×100): cropped = image[0:100, 0:100]\n",
    "<li>Crop center region: cropped = image[100:400, 200:500]\n",
    "<li>Crop from point to end: cropped = image[50:, 50:] (from pixel 50 to image end)\n",
    "<li>Crop bottom-right: cropped = image[-200:, -300:] (negative indexing from end)\n",
    "</ul>\n",
    "\n",
    "<li><b>Dynamic Cropping (using image dimensions):</b>\n",
    "<ul>\n",
    "<li>Get center crop: h, w = image.shape[:2]; cropped = image[h//4:3*h//4, w//4:3*w//4]\n",
    "<li>Crop with margins: margin = 50; cropped = image[margin:-margin, margin:-margin]\n",
    "</ul>\n",
    "\n",
    "<li><b>Important Notes:</b>\n",
    "<ul>\n",
    "<li>Ensure indices are within image bounds to avoid errors\n",
    "<li>startY < endY and startX < endX, otherwise returns empty array\n",
    "<li>For color images, slicing preserves all channels automatically\n",
    "<li>Very fast operation since it's just array indexing\n",
    "<li>Common use cases: ROI (Region of Interest) extraction, removing borders, focusing on specific objects\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a2c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"geeks.png\")\n",
    "cropped = image[0:100,]\n",
    "\n",
    "if image is not None:\n",
    "    cv2.imshow(\"Original\",image)\n",
    "    cv2.imshow(\"Cropped\",cropped)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62b084",
   "metadata": {},
   "source": [
    "## Image Rotation and Flipping\n",
    "\n",
    "<ol>\n",
    "<li><b>Image Rotation</b>\n",
    "<ul>\n",
    "<li>Rotation requires two steps: creating rotation matrix, then applying transformation\n",
    "<li>Rotation is performed around a specified center point\n",
    "<li>Can combine rotation with scaling in single operation\n",
    "</ul>\n",
    "\n",
    "<li><b>cv2.getRotationMatrix2D(center, angle, scale)</b>\n",
    "<ul>\n",
    "<li>Generates a 2D rotation matrix for affine transformation\n",
    "<li><b>center:</b> Tuple (x, y) specifying the center point of rotation. Usually image center: (width//2, height//2)\n",
    "<li><b>angle:</b> Rotation angle in degrees (positive = counter-clockwise, negative = clockwise)\n",
    "<li><b>scale:</b> Scaling factor. 1.0 = no scaling, 0.5 = half size, 2.0 = double size\n",
    "<li>Returns: 2×3 transformation matrix (M) used for rotation\n",
    "<li>Example: M = cv2.getRotationMatrix2D((width//2, height//2), 45, 1.0) rotates 45° counter-clockwise\n",
    "</ul>\n",
    "\n",
    "<li><b>cv2.warpAffine(src, M, dsize, flags, borderMode, borderValue)</b>\n",
    "<ul>\n",
    "<li>Applies affine transformation to an image using the transformation matrix\n",
    "<li><b>src:</b> Source/input image\n",
    "<li><b>M:</b> 2×3 transformation matrix (from getRotationMatrix2D)\n",
    "<li><b>dsize:</b> Size of output image as tuple (width, height). Usually same as original: (width, height)\n",
    "<li><b>flags:</b> Interpolation method (optional, default = cv2.INTER_LINEAR). Options: INTER_NEAREST, INTER_LINEAR, INTER_CUBIC\n",
    "<li><b>borderMode:</b> Pixel extrapolation method for areas outside image (optional, default = cv2.BORDER_CONSTANT)\n",
    "<li><b>borderValue:</b> Value used for constant border (optional, default = 0/black)\n",
    "<li>Returns: Transformed/rotated image\n",
    "</ul>\n",
    "\n",
    "<li><b>Complete Rotation Example:</b>\n",
    "<ul>\n",
    "<li>height, width = image.shape[:2]\n",
    "<li>center = (width // 2, height // 2)\n",
    "<li>M = cv2.getRotationMatrix2D(center, 90, 1.0)\n",
    "<li>rotated = cv2.warpAffine(image, M, (width, height))\n",
    "</ul>\n",
    "\n",
    "<li><b>Image Flipping</b>\n",
    "<ul>\n",
    "<li><b>cv2.flip(src, flipCode)</b> - Simpler operation for mirroring images\n",
    "<li><b>src:</b> Source/input image\n",
    "<li><b>flipCode:</b> Direction of flip\n",
    "  <ul>\n",
    "  <li>0 = Flip vertically (around x-axis, upside down)\n",
    "  <li>1 = Flip horizontally (around y-axis, mirror left-right)\n",
    "  <li>-1 = Flip both vertically and horizontally (180° rotation)\n",
    "  </ul>\n",
    "<li>Returns: Flipped image\n",
    "<li>Example: flipped = cv2.flip(image, 1) for horizontal flip\n",
    "</ul>\n",
    "\n",
    "<li><b>Common Use Cases:</b>\n",
    "<ul>\n",
    "<li>Correcting image orientation (photos taken sideways)\n",
    "<li>Data augmentation for machine learning datasets\n",
    "<li>Creating mirror effects\n",
    "<li>Aligning images for comparison or stitching\n",
    "<li>Artistic effects and transformations\n",
    "</ul>\n",
    "\n",
    "<li><b>Important Notes:</b>\n",
    "<ul>\n",
    "<li>Rotation may crop parts of image if rotated corners exceed output dimensions\n",
    "<li>To avoid cropping, calculate new dimensions: use larger dsize to fit entire rotated image\n",
    "<li>Multiple rotations degrade image quality (repeated interpolation)\n",
    "<li>For 90°, 180°, 270° rotations, cv2.rotate() is more efficient (no interpolation needed)\n",
    "<li>cv2.rotate() options: cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a73b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is not None:\n",
    "    h,w = image.shape[:2]\n",
    "\n",
    "    center = (w//2,h//2)\n",
    "    M = cv2.getRotationMatrix2D(center,90,1.0)\n",
    "    rotated = cv2.warpAffine(image,M,(w,h))\n",
    "\n",
    "    cv2.imshow(\"Rotated\" , rotated)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b2f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n",
      "QFontDatabase: Cannot find font directory /home/mantra/anaconda3/envs/pytorch/lib/python3.11/site-packages/cv2/qt/fonts.\n",
      "Note that Qt no longer ships fonts. Deploy some (from https://dejavu-fonts.github.io/ for example) or switch to fontconfig.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"geeks.png\")\n",
    "\n",
    "if image is not None:\n",
    "    flipped_horizontal = cv2.flip(image,1)\n",
    "    flipped_vertical = cv2.flip(image,0)\n",
    "    flipped_both = cv2.flip(image,-1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"original\",image)\n",
    "    cv2.imshow(\"flipped_h\",flipped_horizontal)\n",
    "    cv2.imshow(\"flipped_v\",flipped_vertical)\n",
    "\n",
    "    cv2.imshow(\"180_rotated\",flipped_both)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dc156",
   "metadata": {},
   "source": [
    "## Basic Image Drawing Techniques\n",
    "\n",
    "<ol>\n",
    "<li><b>Drawing Lines</b>\n",
    "<ul>\n",
    "<li><b>cv2.line(image, start_point, end_point, color, thickness, lineType)</b>\n",
    "<li><b>image:</b> Input image on which to draw (modified in-place)\n",
    "<li><b>start_point:</b> Starting coordinates as tuple (x, y)\n",
    "<li><b>end_point:</b> Ending coordinates as tuple (x, y)\n",
    "<li><b>color:</b> Line color as tuple (B, G, R) for color images, or scalar for grayscale. Example: (0, 255, 0) for green\n",
    "<li><b>thickness:</b> Line thickness in pixels (optional, default = 1)\n",
    "<li><b>lineType:</b> Type of line (optional, default = cv2.LINE_8)\n",
    "  <ul>\n",
    "  <li>cv2.LINE_8 or 8 = 8-connected line (default, smooth)\n",
    "  <li>cv2.LINE_4 or 4 = 4-connected line (less smooth)\n",
    "  <li>cv2.LINE_AA = Anti-aliased line (smoothest, slower)\n",
    "  </ul>\n",
    "<li>Example: cv2.line(image, (50, 50), (200, 200), (255, 0, 0), 3)\n",
    "<li>Returns: Modified image (same as input since modification is in-place)\n",
    "</ul>\n",
    "\n",
    "<li><b>Adding Text</b>\n",
    "<ul>\n",
    "<li><b>cv2.putText(image, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)</b>\n",
    "<li><b>image:</b> Input image on which to draw text\n",
    "<li><b>text:</b> String to be written\n",
    "<li><b>org:</b> Bottom-left corner coordinates of text as tuple (x, y)\n",
    "<li><b>fontFace:</b> Font type. Options include:\n",
    "  <ul>\n",
    "  <li>cv2.FONT_HERSHEY_SIMPLEX = Normal size sans-serif (most common)\n",
    "  <li>cv2.FONT_HERSHEY_PLAIN = Small size sans-serif\n",
    "  <li>cv2.FONT_HERSHEY_DUPLEX = Normal size sans-serif (more complex)\n",
    "  <li>cv2.FONT_HERSHEY_COMPLEX = Normal size serif\n",
    "  <li>cv2.FONT_HERSHEY_TRIPLEX = Normal size serif (more complex)\n",
    "  <li>cv2.FONT_HERSHEY_SCRIPT_SIMPLEX = Handwriting style\n",
    "  <li>cv2.FONT_HERSHEY_SCRIPT_COMPLEX = Handwriting style (more complex)\n",
    "  <li>Add cv2.FONT_ITALIC to any font for italic version\n",
    "  </ul>\n",
    "<li><b>fontScale:</b> Font size multiplier (1.0 = base size, 2.0 = double size)\n",
    "<li><b>color:</b> Text color as tuple (B, G, R)\n",
    "<li><b>thickness:</b> Thickness of text strokes in pixels (optional, default = 1)\n",
    "<li><b>lineType:</b> Type of line used for text (optional, default = cv2.LINE_8). cv2.LINE_AA for anti-aliased\n",
    "<li><b>bottomLeftOrigin:</b> If True, origin is bottom-left; if False, origin is top-left (optional, default = False)\n",
    "<li>Example: cv2.putText(image, 'Hello OpenCV', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "</ul>\n",
    "\n",
    "<li><b>Drawing Circles</b>\n",
    "<ul>\n",
    "<li><b>cv2.circle(image, center, radius, color, thickness, lineType)</b>\n",
    "<li><b>image:</b> Input image on which to draw\n",
    "<li><b>center:</b> Center coordinates as tuple (x, y)\n",
    "<li><b>radius:</b> Radius of circle in pixels\n",
    "<li><b>color:</b> Circle color as tuple (B, G, R)\n",
    "<li><b>thickness:</b> Thickness of circle outline in pixels (optional, default = 1)\n",
    "  <ul>\n",
    "  <li>Positive value = outline thickness\n",
    "  <li>-1 or cv2.FILLED = filled circle\n",
    "  </ul>\n",
    "<li><b>lineType:</b> Type of circle boundary (optional, default = cv2.LINE_8)\n",
    "<li>Example (outline): cv2.circle(image, (100, 100), 50, (0, 0, 255), 2)\n",
    "<li>Example (filled): cv2.circle(image, (100, 100), 50, (0, 0, 255), -1)\n",
    "</ul>\n",
    "\n",
    "<li><b>Drawing Rectangles</b>\n",
    "<ul>\n",
    "<li><b>cv2.rectangle(image, pt1, pt2, color, thickness, lineType)</b>\n",
    "<li><b>image:</b> Input image on which to draw\n",
    "<li><b>pt1:</b> Top-left corner coordinates as tuple (x, y)\n",
    "<li><b>pt2:</b> Bottom-right corner coordinates as tuple (x, y)\n",
    "<li><b>color:</b> Rectangle color as tuple (B, G, R)\n",
    "<li><b>thickness:</b> Thickness of rectangle edges in pixels (optional, default = 1)\n",
    "  <ul>\n",
    "  <li>Positive value = outline thickness\n",
    "  <li>-1 or cv2.FILLED = filled rectangle\n",
    "  </ul>\n",
    "<li><b>lineType:</b> Type of line (optional, default = cv2.LINE_8)\n",
    "<li>Example (outline): cv2.rectangle(image, (50, 50), (200, 150), (255, 0, 0), 3)\n",
    "<li>Example (filled): cv2.rectangle(image, (50, 50), (200, 150), (255, 0, 0), -1)\n",
    "</ul>\n",
    "\n",
    "<li><b>Additional Drawing Functions:</b>\n",
    "<ul>\n",
    "<li><b>cv2.ellipse():</b> Draws elliptical arcs or filled ellipses\n",
    "<li><b>cv2.polylines():</b> Draws polygonal curves (connects multiple points)\n",
    "<li><b>cv2.fillPoly():</b> Fills polygons\n",
    "<li><b>cv2.arrowedLine():</b> Draws an arrow from start to end point\n",
    "</ul>\n",
    "\n",
    "<li><b>Common Use Cases:</b>\n",
    "<ul>\n",
    "<li>Annotating images with labels and bounding boxes\n",
    "<li>Marking detected objects (face detection, object detection)\n",
    "<li>Creating overlays and watermarks\n",
    "<li>Visualizing computer vision results\n",
    "<li>Image augmentation and debugging\n",
    "<li>Creating diagrams and visualizations\n",
    "</ul>\n",
    "\n",
    "<li><b>Important Notes:</b>\n",
    "<ul>\n",
    "<li>All drawing functions modify the image in-place (original image is changed)\n",
    "<li>Use image.copy() before drawing if you need to preserve the original\n",
    "<li>Color values range from 0-255 for each channel\n",
    "<li>Coordinates start at (0, 0) in top-left corner\n",
    "<li>Drawing outside image bounds doesn't cause errors - out-of-bounds parts are ignored\n",
    "<li>For anti-aliased (smoother) shapes, use cv2.LINE_AA as lineType\n",
    "<li>BGR color order (not RGB): (255, 0, 0) is blue, (0, 255, 0) is green, (0, 0, 255) is red\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6015f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
